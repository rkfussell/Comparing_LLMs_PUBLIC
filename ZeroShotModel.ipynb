{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3408e284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a74be04c98346329ba231d948fefcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkf33/.conda/envs/labnotes/lib/python3.9/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model #, model_selection\n",
    "from transformers import BertTokenizer\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import gc         # garbage collect library\n",
    "\n",
    "import utilities as ut\n",
    "import bert_ut as bu \n",
    "import llama_ut as lu\n",
    "import data_utils as du \n",
    "import bow_utils as bow \n",
    "import evals\n",
    "\n",
    "import sys\n",
    "\n",
    "#How many notes files not in the training set?\n",
    "cutoff=50\n",
    "\n",
    "ut.set_seed(0)\n",
    "\n",
    "files=os.listdir('xlsx')\n",
    "random.shuffle(files)\n",
    "\n",
    "#prompt=\"<<SYS>>\\nAnalyze the sentence given. Does the sentence demonstrate a quantitative comparison between data, best fit lines etc? Answer with just yes or no. \\n<</SYS>>\\n [INST]\\n \"\n",
    "\n",
    "prompt=None\n",
    "\n",
    "#chunk by files\n",
    "\n",
    "train=du.dataframe(files[cutoff:], prompt = prompt)\n",
    "val=du.dataframe(files[:cutoff], prompt = prompt)\n",
    "train['Sentences'] = train['Sentences'].astype(str)\n",
    "val['Sentences'] = val['Sentences'].astype(str)\n",
    "\n",
    "testFiles=os.listdir('holdout')\n",
    "test=du.dataframe(testFiles, prompt=prompt, path='holdout')\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "modelpath=\"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\", token='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',\n",
    "    \n",
    "    #attn_implementation=\"flash_attention_2\",  # make sure to have flash-attn pip-installed\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath, use_fast=False, token='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') \n",
    "\n",
    "# simple wrapper around model.generate() \n",
    "def generate(prompt, max_new_tokens = 100): \n",
    "    prompt_tokenized=tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output_tokenized = model.generate(\n",
    "        **prompt_tokenized, \n",
    "        temperature=0.0,\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        pad_token_id = tokenizer.eos_token_id)[0]\n",
    "    \n",
    "    output_tokenized = output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):]\n",
    "    output = tokenizer.decode(output_tokenized)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f14cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens = 100): \n",
    "    prompt_tokenized=tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output_tokenized = model.generate(\n",
    "        **prompt_tokenized, \n",
    "        temperature=0.01,\n",
    "        top_p= 0,\n",
    "        max_new_tokens = max_new_tokens,\n",
    "        pad_token_id = tokenizer.eos_token_id)[0]\n",
    "    \n",
    "    output_tokenized = output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):]\n",
    "    output = tokenizer.decode(output_tokenized)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa90116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f05190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value: 1.6445 seconds\n",
      "Amplitude of 10°: Mean = 1.626\n",
      "SD = 0.109\n",
      "SU = 0.035\n",
      "Amplitude of 20°:\n",
      "Mean = 1.624\n",
      "SD = 0.0878\n",
      "SU = 0.028\n",
      "The standard deviation is closer to the reaction time uncertainty (0.1 seconds).\n",
      "Five consecutive swings per trial would reduce the uncertainty of the period because the overall uncertainty would be divided by five to find the average uncertainty for a single swing.\n",
      "Compared to a group that measured using camera -> their data:\n",
      "10° mean = 1.40 s\n",
      "20° mean = 1.46 s\n",
      "By having three people measure, we were also able to lessen the standard deviation since averaging the data reduces the effect of outliers.\n",
      "Furthermore, the means for both swings were also closest to the expected computed value of 1.645s, demonstrating higher accuracy.\n",
      "t’ for Q1&2 of Unit 1 Part 1:\n",
      "2) As the uncertainty decreased between data sets, the t’ value increased significantly.\n",
      "3) Both t’ values are greater than 3.\n",
      "This implies that there is a distinguishable difference between both data sets, and that we’re possibly measuring different phenomena.\n",
      "Reducing uncertainty will only increase our t’ values, which is undesired as our t’ values already suggest distinguishability between our data sets.\n",
      "Thus we can ascertain the accuracy of our model when comparing its results to known values.\n",
      "and seeing the same difference in measurements.\n",
      "We started out with a 100g mass and conducted 22 trials each at 10 and 20 degrees.\n",
      "The periods recorded display the difference between each pair of start and end times.\n",
      "For the experiment that focused on changing the mass, and whether or not that would effect the period of the pendulum, we found our uncertainties to be similar in magnitude to that of our previous experiment.\n",
      "Their uncertainty was much lower due to the amount of data they collected, and one way in which they collected data was doing multiple readings for each swing.\n",
      "The mean, standard deviation, and uncertainty calculated are the updated measurements now taking to account all the data.\n",
      "As you can see, the uncertainty reduced greatly for most of the intervals, on average decreasing the uncertainty by 0.008.\n",
      "This allowed us to be more sure in the data that we were collecting, as the uncertainty is now lower than before.\n",
      "Thus our expectation returned to our original assumption that the angle difference is indistinguishable.\n",
      "30\n",
      "70\n",
      "Conclusion - 8 cycles of 10° pendulum swing was most accurate (compared to expected value from the Tp equation), but not as precise as other trials (trade off).\n",
      "We think both methods have the same accuracy and precision because we have more information than they did so we can come up with an accurate and precise result and on the other hand, they can look back to their video and measure the exact time of the period of the swing.\n",
      "Choosing to work with 8 swings per measurement allowed us to reduce the impact of the 0.1 seconds of human reaction time and get a more accurate measurement.\n",
      "e) i)In terms of patterns, for both of our methods we had T-values close to 1, meaning that the different datasets are indistinguishable.\n",
      "In terms of the validity of our assumptions, we were proven wrong, as we assumed that a change in mass would affect our period - when we compared our t’ values; however, we found that they were both around 1 - this means that for both of the measured 10 degree and 20 degree angles, changing the mass did not affect the period - as the t’ value was around 1 which means that both of the measured datasets are indistinguishable - we were measuring the same phenomena.\n",
      "Regarding measurement position, our results reflect that we were wrong that measurement position didn’t affect the period, as our t’ value reflected indistinguishability measuring from the bottom of the pendulum arc.\n",
      "This experiment does not fit Hooke’s Law since there is no intercept within the equation and the graph should have reflected a linear relationship.\n",
      "○ We had to shift up the trendline to match points in the middle of the data set in order to calculate chi squared.\n",
      "T’\n",
      "t’\n",
      "We got a bigger number so that means the results are more distinguishable.\n",
      "We were then introduced to the method of least squares:\n",
      "From this, we found that a linear fit is best for the data (the RMSE for the linear fit was about 0.03, while the RMSE for the quadratic fit was 0.04).\n",
      "\tFrom our calculations, we are unable to determine the effect of buoyancy on the acceleration, since our T-prime value was 1.6.\n",
      "However, our calculated distinguishability does not reflect this prediction.\n",
      "It is not conclusive that the period of the pendulums at 10° and 20° is the same/indistinguishable.\n",
      "None of the t’ values were distinguishable or  indistinguishable.\n",
      "At the start of the experiment, we expected the two data sets to be indistinguishable because  the given period equation does not depend on angle measure:\n",
      "In addition, we found that  swinging the pendulum for five periods worked the best for our group because fifteen swings  had too high of a standard deviation, and ten swings took long enough to make our pole shake.\n",
      "This was not the case even though the t’ values showed they were two different phenomena.\n",
      "As we recorded data for more trials and found the k value at different ∆y values, we noticed that the k value steadily decreased by a large margin as the ∆y values increased.\n",
      "This suggests that there is a nonlinear relationship between the displacement and the spring force.\n",
      "This possibly suggests that Hooke’s Law, in this case, fails for large displacements.\n",
      "The most interesting aspect of our second investigation was that the spring followed Hooke’s Law less strictly than the hair tie we used in the first experiment.\n",
      "This is approximately 9–which means that this spring most likely followed a nonlinear relationship between displacement and force, and therefore did not strictly follow Hooke’s Law.\n",
      "Residuals: [ 7.970e-04, -7.189e-04,  7.652e-04,  2.493e-04, -7.666e-04, -7.825e-04,\n",
      "74\n",
      "26\n",
      "Balanced accuracy: \n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "#examples=4\n",
    "pos=train.loc[train['QC'] == 1]\n",
    "neg=train.loc[train['QC'] == 0]\n",
    "\n",
    "\n",
    "prompt='''Below is a json file that has sentences and a classification of whether or not the sentences demonstrates: \n",
    "Comparison of Quantities - Students should apply data analysis tools quantitatively to make some sort of comparison (between data, best fit lines, predictions, etc.  \n",
    "Students use t' (t-prime) values and chi-squared values to compare quantities, however the heading of a table containing these does not count. Students may also compare the uncertainty in the mean. '''\n",
    "\n",
    "prompt+='''\n",
    "    Input:\n",
    "{\n",
    "  \"text\":'''+\"Our t-prime value had an absolute value between 1 and 3, which indicates that it is possible that A and B are the same (that the period of the pendulum is unaffected by the amplitude of the string), but there is not enough evidence to clearly conclude they are indistinguishable.\"+'''\"\n",
    "}\n",
    "Analysis:\n",
    "{\n",
    "  \"Quantatitive Comparison?\": \"Yes\"\n",
    "}'''\n",
    "\n",
    "\n",
    "prompt+='''\n",
    "    Input:\n",
    "{\n",
    "  \"text\":'''+\"To make our chi-squared value close to 1, using our standard deviation of the acceleration from our preliminary tests during last lab session as an estimate of dy, the uncertainty would need to be approximately:\"+'''\"\n",
    "}\n",
    "Analysis:\n",
    "{\n",
    "  \"Quantatitive Comparison?\": \"Yes\"\n",
    "}'''\n",
    "\n",
    "prompt+='''\n",
    "    Input:\n",
    "{\n",
    "  \"text\":'''+\"t’ = 10.09885\"+'''\"\n",
    "}\n",
    "Analysis:\n",
    "{\n",
    "  \"Quantatitive Comparison?\": \"Yes\"\n",
    "}'''\n",
    "prompt+='''\n",
    "    Input:\n",
    "{\n",
    "  \"text\":'''+\"The uncertainty is higher in B (20 degree swing) because we had an outlying data point.\"+'''\"\n",
    "}\n",
    "Analysis:\n",
    "{\n",
    "  \"Quantatitive Comparison?\": \"Yes\"\n",
    "}'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "pos=val.loc[val['QC'] == 1]\n",
    "neg=val.loc[val['QC'] == 0]    \n",
    "    \n",
    "# m=len(pos)\n",
    "m=100\n",
    "    \n",
    "base=prompt\n",
    "\n",
    "\n",
    "FP,TN=0,0\n",
    "for i in range(0,m): #len(neg)):\n",
    "\n",
    "    prompt=base+'''\n",
    "    Input:  \n",
    "    \"text\": \"\"'''+neg.iloc[i]['Sentences']+'''\"\n",
    "    }\n",
    "    Analysis:\n",
    "    {\n",
    "      \"Quantatitive Comparison?\": '''\n",
    "    ans=(generate(prompt, 3) )\n",
    "    if \"Yes\" in ans:\n",
    "        FP+=1\n",
    "        print(neg.iloc[i]['Sentences'])\n",
    "    elif \"No\" in ans:\n",
    "        TN+=1\n",
    "\n",
    "print(FP)\n",
    "print(TN)\n",
    "\n",
    "TP,FN=0,0\n",
    "for i in range(0,m): #len(neg)):\n",
    "\n",
    "    prompt=base+'''\n",
    "    Input:  \n",
    "    \"text\": \"\"'''+pos.iloc[i]['Sentences']+'''\"\n",
    "    }\n",
    "    Analysis:\n",
    "    {\n",
    "      \"Quantatitive Comparison?\": '''\n",
    "    ans=(generate(prompt, 3) )\n",
    "    if \"Yes\" in ans:\n",
    "        TP+=1\n",
    "    elif \"No\" in ans:\n",
    "        FN+=1\n",
    "        print(pos.iloc[i]['Sentences'])\n",
    "        \n",
    "print(TP)\n",
    "print(FN)\n",
    "print(\"Balanced accuracy: \")\n",
    "print((TP+TN)/(2*m))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251383b9-2e2f-45b7-bcf6-562e8817f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amplitude of 10°: Mean = 1.626\n",
      "The standard deviation is closer to the reaction time uncertainty (0.1 seconds).\n",
      "This meansthat the accuracy and precision of the experiment are limited by the group members and not by inaccuracies in the stopwatch.\n",
      "Compared to a group that measured using camera -> their data:\n",
      "We think both methods have the same accuracy and precision because we have more information than they did so we can come up with an accurate and precise result and on the other hand, they can look back to their video and measure the exact time of the period of the swing.\n",
      "However, our method is more efficient because it took much less time and got more data points.\n",
      "This would prevent one person’s poor reaction from skewing the data drastically.\n",
      "Choosing to work with 8 swings per measurement allowed us to reduce the impact of the 0.1 seconds of human reaction time and get a more accurate measurement.\n",
      "Our standard deviations for boththe 10° and 20° swings were lower than those from all other experiments performed (<0.01s), indicating the highest precision.\n",
      "Furthermore, the means for both swings were also closest to the expected computed value of 1.645s, demonstrating higher accuracy.\n",
      "This high accuracy/precision was most likely due to all three group members measuring the period for each trial, as well as using 8 cycles instead of 5 or 1, since we computed that to be the maximum number of cycles used to accurately measure the period.\n",
      "Ten degrees: mean is 1.198 +/- 0.04289 seconds Twenty degrees: mean is 1.386 +/- 0.03416 seconds t’ value is 3.4286\n",
      "Ten degrees: 1.516+/-0.01021 seconds Twenty degrees: 1.265 +/-0.03205 seconds t’  value is 7.4616\n",
      "2) As the uncertainty decreased between data sets, the t’ value increased significantly.\n",
      "3) Both t’ values are greater than 3.\n",
      "This implies that there is a distinguishable difference between both data sets, and that we’re possibly measuring different phenomena.\n",
      "4) As both of our data sets have a t’ value greater than 3, it’ll be best to review our initial assumptions and change our experimental methodology.\n",
      "Pushing on assumptions of a model helps to test whether or not our model matches with our understanding of what determines the period of a pendulum, and what physical factors contribute to the length of its period.\n",
      "Thus we can ascertain the accuracy of our model when comparing its results to known values.\n",
      "We can confirm the distinguishability caused by the difference in angle by changing other variables (mass, point of measurement, etc.)\n",
      "and seeing the same difference in measurements.\n",
      "Still seeing distinguishability in the data when we change these variables confirms the effect of the angle difference.\n",
      "We then conducted the same number of trials at 10 and 20 degrees but with a 200g mass - this ended up being 4 tables of 22 data points each, for a total of 88 measured periods.\n",
      "t’ value for 100g: 1.1066 t’ value for 200g: 0.937\n",
      "The periods recorded display the difference between each pair of start and end times.\n",
      "e) i)In terms of patterns, for both of our methods we had T-values close to 1, meaning that the different datasets are indistinguishable.\n",
      "From this we can infer that we are measuring the same phenomena, and that our experimental changes had no effect on the measured period of the pendulum.\n",
      "In terms of the validity of our assumptions, we were proven wrong, as we assumed that a change in mass would affect our period - when we compared our t’ values; however, we found that they were both around 1 - this means that for both of the measured 10 degree and 20 degree angles, changing the mass did not affect the period - as the t’ value was around 1 which means that both of the measured datasets are indistinguishable - we were measuring the same phenomena.\n",
      "Regarding measurement position, our results reflect that we were wrong that measurement position didn’t affect the period, as our t’ value reflected indistinguishability measuring from the bottom of the pendulum arc.\n",
      "This differs from our result from last week, where our results suggested the data sets were distinguishable.\n",
      "Their uncertainty was much lower due to the amount of data they collected, and one way in which they collected data was doing multiple readings for each swing.\n",
      "In the mass experiment, we employed consecutive swings, which enabled us to gather more data, which in turn reduced the uncertainty by increasing the number of trials.\n",
      "The additional data collected is shown below, collected from multiple swings.\n",
      "As you can see, the uncertainty reduced greatly for most of the intervals, on average decreasing the uncertainty by 0.008.\n",
      "Second, we were interested to see how the weight change of the object being swung by the pendulum would affect the period.\n",
      "At the beginning of Part 2 of Unit 1 we assumed that the angle difference does lead to adistinguishable difference in period since our t’ values derived from Part 1  were greater than a value of 3 (respectively 3.43 and 7.46).\n",
      "However, after continuing to test this assumption in Part 2 we were able to obtain t’ values much closer to 1 (0.937, 1.107, and 1.40).\n",
      "This is because with our mass datasets, our measured t’ values were 0.937 and 1.107, which were close to 1, meaning that our datasets were almost indistinguishable, and that we were measuring the same phenomena.\n",
      "38\n",
      "62\n",
      "We wanted to do multiple trials of this but we were cut short when we had to change gears.\n",
      "Place a weight on the base of the ring stand to prevent wobbling while the pendulum is in motion and data is being recorded.\n",
      "AH: The purpose of these different angles is to measure the effect of air resistance because the longer the arc and the longer the time it spends in the air, the more effect the bob experiences from its surroundings.\n",
      "We would repeat the same experiment, with 10 trials, the apparatus on the table, and  the same people controlling the pendulum and stopwatch.\n",
      "We added more distances along the way, and consequently reduced the number of trials so that we could get a k-value with a lower uncertainty.\n",
      "Allowing for the theraband to stop moving after adding weight to the system helped to minimize this error.\n",
      "Mass will still be added in 50g increments, but the starting mass will be 50g because of the reasons described above.\n",
      "93\n",
      "7\n",
      "Balanced accuracy: \n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "#examples=4\n",
    "pos=train.loc[train['PI'] == 1]\n",
    "neg=train.loc[train['PI'] == 0]\n",
    "\n",
    "                                                                                                                                                                                                                                                                                                                    \n",
    "prompt='''Below is a json file that has sentences and a classification of whether or not the sentences demonstrates: \n",
    "Proposed Iteration - Students should be able to suggest additional rounds of experimentation and choose appropriate improvements. Could be based on experimental evidence.   \n",
    "Must be a sentence in future or present tense that proposes an experimental choice (we could, we will, we are doing). Not something that was done in the past (e.g. this method improved our uncertainty) AND\n",
    "Must have at least one word/phrase you can point to is synonymous with either more measurements (additional angles, new trials) or change/improve (new/different object, new/different method, revised/improved/adjusted/modified experiment, to reduce or account for uncertainty) or plan for next time/ plan for future'''\n",
    "\n",
    "      \n",
    "prompt+='''\n",
    "    Input:\n",
    "{\n",
    "  \"text\":'''+\"For more accurate results the use of a camera to time the oscillations would omit errors due to human reaction time. \"+'''\"\n",
    "}\n",
    "Analysis:\n",
    "{\n",
    "  \"Proposed Iteration?\": \"Yes\"\n",
    "}'''\n",
    "\n",
    "\n",
    "prompt+='''\n",
    "    Input:\n",
    "{\n",
    "  \"text\":'''+\"Continued experimentation\"+'''\"\n",
    "}\n",
    "Analysis:\n",
    "{\n",
    "  \"Proposed Iteration?\": \"No\"\n",
    "}'''\n",
    "\n",
    "prompt+='''\n",
    "    Input:\n",
    "{\n",
    "  \"text\":'''+\"Session 2 new experiment\"+'''\"\n",
    "}\n",
    "Analysis:\n",
    "{\n",
    "  \"Proposed Iteration?\": \"No\"\n",
    "}'''\n",
    "prompt+='''\n",
    "    Input:\n",
    "{\n",
    "  \"text\":'''+\"We could add more trials to improve our uncertainties\"+'''\"\n",
    "}\n",
    "Analysis:\n",
    "{\n",
    "  \"Proposed Iteration?\": \"Yes\"\n",
    "}'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "pos=val.loc[val['PI'] == 1]\n",
    "neg=val.loc[val['PI'] == 0]    \n",
    "    \n",
    "# m=len(pos)\n",
    "m=100\n",
    "    \n",
    "base=prompt\n",
    "\n",
    "\n",
    "FP,TN=0,0\n",
    "for i in range(0,m): #len(neg)):\n",
    "    prompt=base+'''\n",
    "        Input:  \n",
    "        \"text\": \"\"'''+neg.iloc[i]['Sentences']+'''\"\n",
    "        }\n",
    "        Analysis:\n",
    "        {\n",
    "          \"Quantatitive Comparison?\": '''\n",
    "    ans=(generate(prompt, 3) )\n",
    "    if \"Yes\" in ans:\n",
    "        FP+=1\n",
    "        print(neg.iloc[i]['Sentences'])\n",
    "    elif \"No\" in ans:\n",
    "        TN+=1\n",
    "    \n",
    "print(FP)\n",
    "print(TN)\n",
    "\n",
    "TP,FN=0,0\n",
    "for i in range(0,m): #len(neg)):\n",
    "\n",
    "    prompt=base+'''\n",
    "    Input:  \n",
    "    \"text\": \"\"'''+pos.iloc[i]['Sentences']+'''\"\n",
    "    }\n",
    "    Analysis:\n",
    "    {\n",
    "      \"Proposed Iteration?\": '''\n",
    "    ans=(generate(prompt, 3) )\n",
    "    if \"Yes\" in ans:\n",
    "        TP+=1\n",
    "    elif \"No\" in ans:\n",
    "        FN+=1\n",
    "        print(pos.iloc[i]['Sentences'])\n",
    "        \n",
    "print(TP)\n",
    "print(FN)\n",
    "print(\"Balanced accuracy: \")\n",
    "print((TP+TN)/(2*m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85006e-e50b-46c8-9adb-6b726d4fbaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
